{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e72b891",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [ARMA Model (df1)](#arma-model-df1)\n",
    "   - [Data Preparation](#data-preparation-df1)\n",
    "   - [Preprocessing](#preprocessing-df1)\n",
    "   - [Modeling](#modeling-df1)\n",
    "   - [Conclusion](#conclusion-df1)\n",
    "3. [GARCH Model (df2)](#garch-model-df2)\n",
    "   - [Data Preparation](#data-preparation-df2)\n",
    "   - [Preprocessing](#preprocessing-df2)\n",
    "   - [Modeling](#modeling-df2)\n",
    "   - [Conclusion](#conclusion-df2)\n",
    "4. [LSTM Model (df3)](#lstm-model-df3)\n",
    "   - [Data Preparation](#data-preparation-df3)\n",
    "   - [Preprocessing](#preprocessing-df3)\n",
    "   - [Modeling](#modeling-df3)\n",
    "   - [Conclusion](#conclusion-df3)\n",
    "5. [Summary and Conclusions](#summary-and-conclusions)\n",
    "6. [References](#references)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d726895",
   "metadata": {},
   "source": [
    "Before delving into the modeling process, it's essential to organize the dataset appropriately for each modeling technique. In our approach, we'll segment the dataset into three distinct dataframes, each tailored for a specific modeling technique. This segmentation ensures that we apply the most suitable preprocessing and modeling strategies for each model. Let's outline the breakdown:\n",
    "\n",
    "**ARMA Model (df1):** \n",
    "* This dataframe will focus on preparing the data for the AutoRegressive Moving Average (ARMA) model. It includes essential columns such as 'Date' and 'Adj Close', optimized for time-series analysis.\n",
    "\n",
    "**GARCH Model (df2):**\n",
    "* Here, we'll structure the data to suit the Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) model. The dataframe will contain 'Date' and 'pct_change' columns, crucial for capturing volatility patterns.\n",
    "\n",
    "**LSTM Model (df3):**\n",
    "* For the Long Short-Term Memory (LSTM) model, we'll set up a dataframe with features like 'Open', 'High', 'Low', 'Close', 'Adj Close', and 'Volume'. This comprehensive dataset enables the LSTM model to learn intricate temporal dependencies and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4d2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76601610",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "The data comes from the Kaggle: a free, open-source data-sharing portal with a massive range of datasets.\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88295a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open_Delta</th>\n",
       "      <th>High</th>\n",
       "      <th>High_Delta</th>\n",
       "      <th>Low</th>\n",
       "      <th>Low_Delta</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_Delta</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Adj Close_Delta</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume_Delta</th>\n",
       "      <th>daily_return Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41094000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>4.620</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>3.742</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>3.840</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>3.840</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>25699000</td>\n",
       "      <td>-15395000.0</td>\n",
       "      <td>-0.125683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>4.000</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>3.166</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>3.222</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>3.222</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>34334500</td>\n",
       "      <td>8635500.0</td>\n",
       "      <td>-0.160937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>3.280</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>3.326</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>2.996</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>3.160</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>3.160</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>34608500</td>\n",
       "      <td>274000.0</td>\n",
       "      <td>-0.019243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>3.228</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>3.504</td>\n",
       "      <td>0.178</td>\n",
       "      <td>3.114</td>\n",
       "      <td>0.118</td>\n",
       "      <td>3.492</td>\n",
       "      <td>0.332</td>\n",
       "      <td>3.492</td>\n",
       "      <td>0.332</td>\n",
       "      <td>38557000</td>\n",
       "      <td>3948500.0</td>\n",
       "      <td>0.105063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Open  Open_Delta   High  High_Delta    Low  Low_Delta  Close  \\\n",
       "0  2010-07-01  5.000         NaN  5.184         NaN  4.054        NaN  4.392   \n",
       "1  2010-07-02  4.600      -0.400  4.620      -0.564  3.742     -0.312  3.840   \n",
       "2  2010-07-06  4.000      -0.600  4.000      -0.620  3.166     -0.576  3.222   \n",
       "3  2010-07-07  3.280      -0.720  3.326      -0.674  2.996     -0.170  3.160   \n",
       "4  2010-07-08  3.228      -0.052  3.504       0.178  3.114      0.118  3.492   \n",
       "\n",
       "   Close_Delta  Adj Close  Adj Close_Delta    Volume  Volume_Delta  \\\n",
       "0          NaN      4.392              NaN  41094000           NaN   \n",
       "1       -0.552      3.840           -0.552  25699000   -15395000.0   \n",
       "2       -0.618      3.222           -0.618  34334500     8635500.0   \n",
       "3       -0.062      3.160           -0.062  34608500      274000.0   \n",
       "4        0.332      3.492            0.332  38557000     3948500.0   \n",
       "\n",
       "   daily_return Adj Close  \n",
       "0                     NaN  \n",
       "1               -0.125683  \n",
       "2               -0.160937  \n",
       "3               -0.019243  \n",
       "4                0.105063  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/TSLA_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6b148",
   "metadata": {},
   "source": [
    "1. **ARMA Model (df1):** \n",
    "**Data Characteristics:** \n",
    "* ARMA (AutoRegressive Moving Average) models are well-suited for stationary time series data, which exhibit constant statistical properties over time.\n",
    "\n",
    "**Preprocessing Approach:**\n",
    "* The provided data seems to consist of daily stock prices (like 'Adj Close') and their changes over time.\n",
    "* In preprocessing, standardization of the 'value' column (representing stock prices) has been done to ensure that the data has a mean of 0 and a standard deviation of 1. This is crucial for ARMA modeling as it assumes normally distributed stationary data.\n",
    "\n",
    "\n",
    "**Modeling Stage:**\n",
    "* ARMA models are used for modeling the autocorrelation in the data and predicting future values based on past observations.\n",
    "* With the preprocessed data, the ARMA model can be fitted to capture the linear dependencies between past and present values, aiding in predicting future stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9242f32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>3.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>3.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>3.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>3.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-13</td>\n",
       "      <td>3.628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  value\n",
       "3  2010-07-07  3.160\n",
       "4  2010-07-08  3.492\n",
       "5  2010-07-09  3.480\n",
       "6  2010-07-12  3.410\n",
       "7  2010-07-13  3.628"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 'Date' and 'Adj Close' columns from df and renaming 'Adj Close' to 'Value'\n",
    "df1 = df[['Date', 'Adj Close']].rename(columns={'Adj Close': 'value'})\n",
    "\n",
    "# Displaying the first few rows of df1 to verify the changes\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94d56c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranges of features:\n",
      "value    4.660569\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any categorical variables\n",
    "categorical_columns = df1.select_dtypes(include=['object']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    # Create dummy or indicator features for categorical variables\n",
    "    df1 = pd.get_dummies(df1, columns=categorical_columns)\n",
    "\n",
    "# Standardize the magnitude of numeric features using a scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df1[['value']])\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=['value'])\n",
    "\n",
    "# Split into testing and training datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, df1['value'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the range of features\n",
    "feature_ranges = X_train.max() - X_train.min()\n",
    "print(\"Ranges of features:\")\n",
    "print(feature_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5df2d",
   "metadata": {},
   "source": [
    "In summary, standardization ensures fair treatment of all features in the model, regardless of their original scale or units. The feature range check helps ensure that after standardization, all features have reasonable variations that align with their natural characteristics.\n",
    "\n",
    "In our case, after standardization, the range of values for the 'Adj Close' feature is approximately 4.660569. This means that the standardized 'Adj Close' prices have a reasonable variation, indicating that they are appropriately scaled for inclusion in the model. This information provides further assurance that the preprocessing steps have been applied effectively, setting the stage for robust modeling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a3d3b",
   "metadata": {},
   "source": [
    "2. **GARCH Model (df2):**\n",
    "\n",
    "**Data Characteristics:** \n",
    "* GARCH (Generalized AutoRegressive Conditional Heteroskedasticity) models are suitable for time series data with volatility clustering, where periods of high volatility tend to cluster together.\n",
    "\n",
    "\n",
    "**Preprocessing Approach:**\n",
    "* The data for this model consists of percentage changes ('pct_change') of the 'Adj Close' prices, which is a common input for GARCH models.\n",
    "* Similar to the ARMA preprocessing, standardization has been performed on the 'value' column to ensure the data meets the assumptions of the GARCH model.\n",
    "\n",
    "\n",
    "**Modeling Stage:**\n",
    "* GARCH models are specifically designed to model the volatility clustering phenomenon often observed in financial time series.\n",
    "* By fitting a GARCH model to the preprocessed data, one can capture the time-varying volatility and make predictions about future volatility levels, which is valuable for risk management and option pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266bb1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>-1.924271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>10.506329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>-0.343643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>-2.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-13</td>\n",
       "      <td>6.392962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      value\n",
       "3  2010-07-07  -1.924271\n",
       "4  2010-07-08  10.506329\n",
       "5  2010-07-09  -0.343643\n",
       "6  2010-07-12  -2.011494\n",
       "7  2010-07-13   6.392962"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df\n",
    "df_copy['pct_change'] = 100*df_copy['Adj Close'].pct_change()\n",
    "df_copy.dropna(inplace=True)\n",
    "df2 = df_copy.drop(columns=['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'])\n",
    "# Selecting 'Date' and 'pct_change' columns from df and renaming 'pct_change' to 'Value'\n",
    "df2 = df2[['Date', 'pct_change']].rename(columns={'pct_change': 'value'})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d9a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranges of features:\n",
      "value    12.47568\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any categorical variables\n",
    "categorical_columns = df2.select_dtypes(include=['object']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    # Create dummy or indicator features for categorical variables\n",
    "    df2 = pd.get_dummies(df2, columns=categorical_columns)\n",
    "\n",
    "# Standardize the magnitude of numeric features using a scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df2[['value']])\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=['value'])\n",
    "\n",
    "# Split into testing and training datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, df2['value'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the range of features\n",
    "feature_ranges = X_train.max() - X_train.min()\n",
    "print(\"Ranges of features:\")\n",
    "print(feature_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52d3ca",
   "metadata": {},
   "source": [
    "\n",
    "Certainly! Here's an example summary for the preprocessing of df2:\n",
    "\n",
    "In summary, the preprocessing steps for df2, geared towards preparing data for the GARCH model, ensure that the dataset is appropriately structured and scaled for accurate modeling.\n",
    "\n",
    "Standardization of the percentage change in 'Adj Close' prices is a critical step in ensuring fair treatment of features in the model. This process transforms the data to have a mean of 0 and a standard deviation of 1, allowing for consistent interpretation and analysis across different features.\n",
    "\n",
    "After standardization, the feature range check reveals that the range of values for the standardized percentage change is approximately 12.47568. This indicates that the data exhibits reasonable variation, ensuring that no single feature dominates the modeling process due to differences in scale.\n",
    "\n",
    "Overall, these preprocessing steps lay a solid foundation for training the GARCH model, providing confidence that the model will be able to effectively capture volatility patterns in the financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156e739",
   "metadata": {},
   "source": [
    "3. **LSTM Model (df3):**\n",
    "\n",
    "**Data Characteristics:**\n",
    "* LSTM (Long Short-Term Memory) models are a type of recurrent neural network (RNN) that excel at capturing long-term dependencies and patterns in sequential data.\n",
    "\n",
    "\n",
    "**Preprocessing Approach:**\n",
    "* Unlike the previous models, the data here contains multiple features such as 'Open', 'High', 'Low', 'Close', 'Adj Close', and 'Volume'.\n",
    "* Preprocessing involves standardization of all numeric features using a scaler, ensuring that the magnitudes of different features do not bias the LSTM model during training.\n",
    "\n",
    "\n",
    "**Modeling Stage:**\n",
    "* LSTMs are particularly effective for modeling complex, non-linear relationships in sequential data.\n",
    "* With the preprocessed data, an LSTM model can be trained to learn the temporal patterns and dependencies present in the historical stock price data, potentially leading to more accurate predictions of future stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb2e9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.280</td>\n",
       "      <td>3.326</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.160</td>\n",
       "      <td>3.160</td>\n",
       "      <td>34608500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.228</td>\n",
       "      <td>3.504</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.492</td>\n",
       "      <td>3.492</td>\n",
       "      <td>38557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.516</td>\n",
       "      <td>3.580</td>\n",
       "      <td>3.310</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.480</td>\n",
       "      <td>20253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.590</td>\n",
       "      <td>3.614</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.410</td>\n",
       "      <td>3.410</td>\n",
       "      <td>11012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.478</td>\n",
       "      <td>3.728</td>\n",
       "      <td>3.380</td>\n",
       "      <td>3.628</td>\n",
       "      <td>3.628</td>\n",
       "      <td>13400500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Open   High    Low  Close  Adj Close    Volume\n",
       "3  3.280  3.326  2.996  3.160      3.160  34608500\n",
       "4  3.228  3.504  3.114  3.492      3.492  38557000\n",
       "5  3.516  3.580  3.310  3.480      3.480  20253000\n",
       "6  3.590  3.614  3.400  3.410      3.410  11012500\n",
       "7  3.478  3.728  3.380  3.628      3.628  13400500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7bd2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranges of features:\n",
      "Open          4.704777\n",
      "High          4.659606\n",
      "Low           4.703418\n",
      "Close         4.658829\n",
      "Adj Close     4.658829\n",
      "Volume       10.697265\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any categorical variables\n",
    "categorical_columns = df3.select_dtypes(include=['object']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    # Create dummy or indicator features for categorical variables\n",
    "    df3 = pd.get_dummies(df3, columns=categorical_columns)\n",
    "\n",
    "# Standardize the magnitude of numeric features using a scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df3)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df3.columns)\n",
    "\n",
    "# Split into testing and training datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, df3['Close'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the range of features\n",
    "feature_ranges = X_train.max() - X_train.min()\n",
    "print(\"Ranges of features:\")\n",
    "print(feature_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2760464",
   "metadata": {},
   "source": [
    "In summary, the preprocessing steps for df3, tailored for training an LSTM model, ensure that the dataset is appropriately structured and scaled for effective sequential data analysis.\n",
    "\n",
    "Standardization of all numeric features, including 'Open', 'High', 'Low', 'Close', 'Adj Close', and 'Volume', is crucial for maintaining consistency in the model training process. This process transforms the data to have a mean of 0 and a standard deviation of 1, facilitating the learning of patterns and dependencies by the LSTM model.\n",
    "\n",
    "After standardization, the feature range check reveals that the ranges of values for the standardized features vary:\n",
    "\n",
    "'Open': Approximately 4.704777\n",
    "'High': Approximately 4.659606\n",
    "'Low': Approximately 4.703418\n",
    "'Close': Approximately 4.658829\n",
    "'Adj Close': Approximately 4.658829\n",
    "'Volume': Approximately 10.697265\n",
    "These ranges indicate that the standardized features exhibit reasonable variations, ensuring that no single feature dominates the model training process due to differences in scale. The wider range observed for 'Volume' compared to other features is expected, as trading volumes often vary significantly across different time periods.\n",
    "\n",
    "Overall, these preprocessing steps establish a solid groundwork for training the LSTM model, enabling it to effectively capture temporal dependencies and patterns in the financial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fb858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
